#!/usr/bin/env python3
# Sigma CLI Dedicated Converter
# Class to convert Sigma rules to Lucene queries and create Detection Rules using Sigma CLI

import subprocess
import json
import tempfile
import os
import re
from pathlib import Path
from typing import Dict, Any, List, Optional
import yaml


class SigmaCLIConverter:
    """Converter using only Sigma CLI (handles pure conversion functionality only)"""
    
    def __init__(self, sigma_cli_path: str = "sigma"):
        # Initialize Sigma CLI Converter
        self.sigma_cli_path = sigma_cli_path
    
    def load_sigma_rule(self, file_path: str) -> dict:
        """Load a Sigma rule file."""
        with open(file_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
        
    def validate_sigma_rule(self, sigma_rule_path: str) -> bool:
        # Validate Sigma rule
        try:
            cmd = [
                self.sigma_cli_path, "check",
                sigma_rule_path
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )
            
            return True
            
        except subprocess.CalledProcessError:
            return False
    
    def convert_to_lucene(self, sigma_rule_path: str, pipeline: str) -> str:
        # Convert Sigma rule to Lucene query
        try:
            cmd = [
                self.sigma_cli_path, "convert",
                "-t", "lucene",
                "-p", pipeline,
                sigma_rule_path
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )
            
            lucene_query = result.stdout.strip()

            return lucene_query
            
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"[ERROR] Sigma CLI conversion failed: {e.stderr}")

    def convert_sigma_rule_to_lucene(self, sigma_rule: Dict[str, Any], 
                               pipeline: str) -> str:
        """
        Sigma rule 딕셔너리를 임시 파일로 저장하고 Lucene으로 변환
        
        Args:
            sigma_rule: Sigma rule 딕셔너리
            pipeline: 사용할 처리 파이프라인
            
        Returns:
            변환된 Lucene 쿼리 문자열
        """
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yml', delete=False) as temp_file:
            yaml.dump(sigma_rule, temp_file, default_flow_style=False, allow_unicode=True)
            temp_file_path = temp_file.name
        
        try:
            return self.convert_to_lucene(temp_file_path, pipeline)
        finally:
            # 임시 파일 삭제
            os.unlink(temp_file_path)
    
    def convert_to_detection_rule(self, sigma_rule: Dict[str, Any], 
                                pipeline: str = None,
                                additional_fields: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        # Convert Sigma rule to Detection Rule
        # If pipeline is not specified, select automatically
        if pipeline is None:
            pipeline = self._select_appropriate_pipeline(sigma_rule)
        
        # Create Lucene query using Sigma CLI
        lucene_query = self.convert_sigma_rule_to_lucene(sigma_rule, pipeline)
        
        # Create Detection Rule structure
        detection_rule = self._create_detection_rule_structure(sigma_rule, lucene_query, additional_fields)
        
        return detection_rule
    
    def _create_detection_rule_structure(self, sigma_rule: Dict[str, Any], 
                                       lucene_query: str,
                                       additional_fields: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create Detection Rule structure
        
        Args:
            sigma_rule: Sigma rule dictionary
            lucene_query: Lucene query string
            additional_fields: Additional fields to set (optional)
            
        Returns:
            Detection Rule dictionary
        """
        # Extract basic information
        title = sigma_rule.get('title', 'Unknown Rule')
        rule_id = sigma_rule.get('id') or self._generate_rule_id(title)
        description = sigma_rule.get('description', '')
        level = sigma_rule.get('level', 'medium')
        tags = sigma_rule.get('tags', [])
        
        # Map risk level to risk score
        risk_score_map = {'low': 21, 'medium': 47, 'high': 73, 'critical': 99}
        risk_score = risk_score_map.get(level.lower(), 47)
        
        # Create Detection Rule structure
        detection_rule = {
            "rule_id": rule_id,
            "risk_score": risk_score,
            "description": description,
            "name": title,
            "severity": level,
            "type": "query",
            "language": "lucene",
            "query": lucene_query,  # Use Lucene query generated by Sigma CLI
            "filters": self._get_filters(sigma_rule),
            "enabled": True,
            "interval": "5m",
            "from": "now-70m",
            "max_signals": 100,
            "tags": tags,
            "to": "now",
            "references": [],
            "threat": [],
            "version": 1,
            "exceptions_list": [],
            "related_integrations": [],
            "required_fields": [],
            "setup": "",
            "author": [sigma_rule.get('author', "none")],
            "false_positives": sigma_rule.get('falsepositives', []),
            "license": sigma_rule.get('license', 'DRL'),
            "output_index": "",
            "index":["apm-*-transaction*","auditbeat-*","endgame-*","filebeat-*","logs-*","packetbeat-*","traces-apm*","winlogbeat-*","-*elastic-cloud-logs-*"],
            "meta": {
                "kibana_siem_app_url": ""
            },
            "actions":[]
        }
        
        # If additional fields are provided, overwrite existing fields or add new fields
        if additional_fields:
            detection_rule.update(additional_fields)
        
        return detection_rule
    
    def _generate_rule_id(self, title: str) -> str:
        """Generate rule ID from title"""
        # Remove special characters and convert to lowercase
        rule_id = re.sub(r'[^a-zA-Z0-9_]', '_', title.lower())
        # Remove consecutive underscores
        rule_id = re.sub(r'_+', '_', rule_id)
        # Remove leading and trailing underscores
        rule_id = rule_id.strip('_')
        # Convert underscores to hyphens
        rule_id = rule_id.replace('_', '-')
        return rule_id
    
    def _get_filters(self, sigma_rule: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Create filters from Sigma rule"""
        logsource = sigma_rule.get('logsource', {})
        category = logsource.get('category', '')
        
        filters = []
        
        # Add default filters for each category
        if category == 'process_creation':
            filters.append({
                "query": {
                    "match": {
                        "event.action": {
                            "type": "phrase",
                            "query": "Process Create (rule: ProcessCreate)"
                        }
                    }
                }
            })
        elif category == 'file_event':
            filters.append({
                "query": {
                    "match": {
                        "event.action": {
                            "type": "phrase", 
                            "query": "File Create (rule: FileCreate)"
                        }
                    }
                }
            })
        elif category == 'network_connection':
            filters.append({
                "query": {
                    "match": {
                        "event.action": {
                            "type": "phrase",
                            "query": "Network connection detected (rule: NetworkConnect)"
                        }
                    }
                }
            })
        
        return filters
    
    def _select_appropriate_pipeline(self, sigma_rule: Dict[str, Any]) -> str:
        """
        Select appropriate pipeline based on Sigma rule's logsource
        
        Args:
            sigma_rule: Sigma rule dictionary
            
        Returns:
            The name of the selected pipeline
        """
        logsource = sigma_rule.get('logsource', {})
        product = logsource.get('product', '').lower()
        service = logsource.get('service', '').lower()
        category = logsource.get('category', '').lower()
        
        # Windows events related services/categories use ecs_windows pipeline
        windows_services = [
            'sysmon',
            'windefend',
            'taskscheduler'
        ]
        
        windows_categories = [
            'pipe_created',
            'network_connection', 
            'image_load',
            'driver_load',
            'dns_query',
            'create_stream_hash',
            'create_remote_thread'
        ]
        
        # Check services
        if any(service == s for s in windows_services) or service.startswith('terminalservices'):
            return 'ecs_windows'
        
        # Check categories
        if any(category == c for c in windows_categories) or category.startswith('file_'):
            return 'ecs_windows'
        
        # PowerShell related categories use sysmon pipeline
        if category.startswith('ps_'):
            return 'sysmon'
        
        # WMI events use ecs_windows_old pipeline
        if category == 'wmi_event':
            return 'ecs_windows_old'
        
        # Kubernetes events
        if product == 'kubernetes':
            return 'ecs_kubernetes'
        
        # Zeek network logs
        if product == 'zeek':
            return 'ecs_zeek_beats'
        
        # Default to ecs_windows
        return 'ecs_windows'
    
    def convert_file(self, input_file: str, output_file: Optional[str] = None, 
                    pipeline: str = None,
                    additional_fields: Optional[Dict[str, Any]] = None) -> str:
        """
        Convert Sigma rule file to Kibana Detection Rule JSON
        
        Args:
            input_file: Input Sigma rule file path
            output_file: Output JSON file path (optional)
            pipeline: Processing pipeline to use
            additional_fields: Additional fields to set (optional)
            
        Returns:
            Output file path
        """
        # Load Sigma rule
        sigma_rule = self.load_sigma_rule(input_file)
        
        # Convert to Detection Rule
        detection_rule = self.convert_to_detection_rule(sigma_rule, pipeline, additional_fields)
        
        # Determine output file name
        if output_file is None:
            input_path = Path(input_file)
            output_file = str(input_path.with_suffix('.detection_rule.json'))
        
        # Create output directory if it doesn't exist
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Save to JSON file
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(detection_rule, f, indent=2, ensure_ascii=False)
        
        return output_file